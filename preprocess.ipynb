{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66ea136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\nishc\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\nishc\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: click in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nishc\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c83431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nishc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nishc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nishc\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4772be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b8a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before cleaning: (23196, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>news_url</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>tweet_num</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kandi Burruss Explodes Over Rape Accusation on...</td>\n",
       "      <td>http://toofab.com/2017/05/08/real-housewives-a...</td>\n",
       "      <td>toofab.com</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People's Choice Awards 2018: The best red carp...</td>\n",
       "      <td>https://www.today.com/style/see-people-s-choic...</td>\n",
       "      <td>www.today.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sophia Bush Sends Sweet Birthday Message to 'O...</td>\n",
       "      <td>https://www.etonline.com/news/220806_sophia_bu...</td>\n",
       "      <td>www.etonline.com</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colombian singer Maluma sparks rumours of inap...</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-33655...</td>\n",
       "      <td>www.dailymail.co.uk</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gossip Girl 10 Years Later: How Upper East Sid...</td>\n",
       "      <td>https://www.zerchoo.com/entertainment/gossip-g...</td>\n",
       "      <td>www.zerchoo.com</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Kandi Burruss Explodes Over Rape Accusation on...   \n",
       "1  People's Choice Awards 2018: The best red carp...   \n",
       "2  Sophia Bush Sends Sweet Birthday Message to 'O...   \n",
       "3  Colombian singer Maluma sparks rumours of inap...   \n",
       "4  Gossip Girl 10 Years Later: How Upper East Sid...   \n",
       "\n",
       "                                            news_url        source_domain  \\\n",
       "0  http://toofab.com/2017/05/08/real-housewives-a...           toofab.com   \n",
       "1  https://www.today.com/style/see-people-s-choic...        www.today.com   \n",
       "2  https://www.etonline.com/news/220806_sophia_bu...     www.etonline.com   \n",
       "3  https://www.dailymail.co.uk/news/article-33655...  www.dailymail.co.uk   \n",
       "4  https://www.zerchoo.com/entertainment/gossip-g...      www.zerchoo.com   \n",
       "\n",
       "   tweet_num  real  \n",
       "0         42     1  \n",
       "1          0     1  \n",
       "2         63     1  \n",
       "3         20     1  \n",
       "4         38     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "RAW_PATH = \"data/FakeNewsNet.csv\"   # adjust path if needed\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "print(\"Shape before cleaning:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e3b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls before: {'title': 0, 'label': 0, 'tweet_num': 0}\n",
      "Duplicates before: 170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>Eva Mendes Tells All About Being A Working Mom...</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9764</th>\n",
       "      <td>Behind The Scenes From Matt Hunter and Lele Po...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16092</th>\n",
       "      <td>All the Surprise Songs Taylor Swift Has Perfor...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  label  tweet_num\n",
       "5034   Eva Mendes Tells All About Being A Working Mom...      1         68\n",
       "9764   Behind The Scenes From Matt Hunter and Lele Po...      1         43\n",
       "16092  All the Surprise Songs Taylor Swift Has Perfor...      0          5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = df[['title', 'real', 'tweet_num']].copy()\n",
    "df.rename(columns={'real':'label'}, inplace=True)  # 1 = real, 0 = fake\n",
    "\n",
    "print(\"Nulls before:\", df.isnull().sum().to_dict())\n",
    "print(\"Duplicates before:\", df.duplicated().sum())\n",
    "df.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1695c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls after: {'title': 0, 'label': 0, 'tweet_num': 0}\n",
      "Duplicates after: 0\n",
      "Shape after basic cleaning: (23026, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    17385\n",
       "0     5641\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = df.dropna(subset=['title', 'label'])\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"Nulls after:\", df.isnull().sum().to_dict())\n",
    "print(\"Duplicates after:\", df.duplicated().sum())\n",
    "print(\"Shape after basic cleaning:\", df.shape)\n",
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)   # remove URLs\n",
    "    text = re.sub(r'<.*?>', ' ', text)              # remove HTML\n",
    "    text = re.sub(r'[@#]\\w+', ' ', text)            # remove @mentions & #hashtags\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)           # keep only letters\n",
    "    tokens = []\n",
    "    for w in text.split():\n",
    "        if w in stop_words or len(w) < 3:\n",
    "            continue\n",
    "        tokens.append(lemmatizer.lemmatize(w))\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05149821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty rows after cleaning: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kandi Burruss Explodes Over Rape Accusation on...</td>\n",
       "      <td>kandi burruss explodes rape accusation real ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People's Choice Awards 2018: The best red carp...</td>\n",
       "      <td>people choice award best red carpet look</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sophia Bush Sends Sweet Birthday Message to 'O...</td>\n",
       "      <td>sophia bush sends sweet birthday message one t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colombian singer Maluma sparks rumours of inap...</td>\n",
       "      <td>colombian singer maluma spark rumour inappropr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gossip Girl 10 Years Later: How Upper East Sid...</td>\n",
       "      <td>gossip girl year later upper east siders shock...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gwen Stefani Got Dumped by Blake Shelton Over ...</td>\n",
       "      <td>gwen stefani got dumped blake shelton jealousy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Broward County Sheriff Fired For Lying About P...</td>\n",
       "      <td>broward county sheriff fired lying parkland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amber Rose Shuts Down French Montana Dating Ru...</td>\n",
       "      <td>amber rose shuts french montana dating rumor c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mindy Kaling makes first post-baby appearance ...</td>\n",
       "      <td>mindy kaling make first post baby appearance d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katharine McPhee Butchers Tony Nominations: “I...</td>\n",
       "      <td>katharine mcphee butcher tony nomination drinking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Kandi Burruss Explodes Over Rape Accusation on...   \n",
       "1  People's Choice Awards 2018: The best red carp...   \n",
       "2  Sophia Bush Sends Sweet Birthday Message to 'O...   \n",
       "3  Colombian singer Maluma sparks rumours of inap...   \n",
       "4  Gossip Girl 10 Years Later: How Upper East Sid...   \n",
       "5  Gwen Stefani Got Dumped by Blake Shelton Over ...   \n",
       "6  Broward County Sheriff Fired For Lying About P...   \n",
       "7  Amber Rose Shuts Down French Montana Dating Ru...   \n",
       "8  Mindy Kaling makes first post-baby appearance ...   \n",
       "9  Katharine McPhee Butchers Tony Nominations: “I...   \n",
       "\n",
       "                                         clean_title  label  \n",
       "0  kandi burruss explodes rape accusation real ho...      1  \n",
       "1           people choice award best red carpet look      1  \n",
       "2  sophia bush sends sweet birthday message one t...      1  \n",
       "3  colombian singer maluma spark rumour inappropr...      1  \n",
       "4  gossip girl year later upper east siders shock...      1  \n",
       "5  gwen stefani got dumped blake shelton jealousy...      0  \n",
       "6        broward county sheriff fired lying parkland      0  \n",
       "7  amber rose shuts french montana dating rumor c...      0  \n",
       "8  mindy kaling make first post baby appearance d...      1  \n",
       "9  katharine mcphee butcher tony nomination drinking      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['clean_title'] = df['title'].apply(clean_text)\n",
    "\n",
    "# Drop empty rows after cleaning\n",
    "empty_mask = df['clean_title'].str.len() == 0\n",
    "print(\"Empty rows after cleaning:\", int(empty_mask.sum()))\n",
    "df = df[~empty_mask].reset_index(drop=True)\n",
    "\n",
    "df[['title','clean_title','label']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13bb42a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (23017, 4)\n",
      "Label distribution:\n",
      " label\n",
      "1    0.755\n",
      "0    0.245\n",
      "Name: proportion, dtype: float64\n",
      "Avg. words per title: 7.851153495242647\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Final shape:\", df.shape)\n",
    "print(\"Label distribution:\\n\", df['label'].value_counts(normalize=True).round(3))\n",
    "print(\"Avg. words per title:\", df['clean_title'].str.split().str.len().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e3bcf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ✅ -> data/cleaned_fakenews.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CLEAN_PATH = \"data/cleaned_fakenews.csv\"\n",
    "df[['title','clean_title','label','tweet_num']].to_csv(CLEAN_PATH, index=False)\n",
    "print(\"Saved ✅ ->\", CLEAN_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
